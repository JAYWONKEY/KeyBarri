import os
os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = "hide"
import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import google.generativeai as genai
from dotenv import load_dotenv
import time
import uuid
import pygame
from gtts import gTTS
import re
# 25.04.30ì¼ ì¶”ê°€ 
import fitz  # PyMuPDF
import os

# 25.05.01 í„°ë¯¸ë„ ì—ëŸ¬.txt ì¶”ê°€ 
import traceback 
from datetime import datetime

def log_error(err_msg):
    with open("err_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[{datetime.now()}] ì—ëŸ¬ ë°œìƒ: \n{err_msg}\n\n")


# 25.04.29 ê¸°ëŠ¥ ì¶”ê°€ : def clean_text_for_tts(text)
def clean_text_for_tts(text):
        """TTSë¥¼ ìœ„í•œ í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜"""
        # ë§ˆí¬ë‹¤ìš´ êµµì€ ê¸€ì”¨ í‘œì‹œ ì œê±°
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        # ë§ˆí¬ë‹¤ìš´ ì´íƒ¤ë¦­ì²´ í‘œì‹œ ì œê±°
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        # ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ë° í…ìŠ¤íŠ¸ ì œê±°
        text = re.sub(r'ì°¸ê³ :', 'ì°¸ê³  ì‚¬í•­ìœ¼ë¡œ', text)
        text = re.sub(r'[\[\]\(\)\{\}]', '', text)
        # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ í†µì¼
        text = re.sub(r'\n+', '\n', text)
        # ì¤„ë°”ê¿ˆì„ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ êµ¬ë¶„ìœ¼ë¡œ ë³€í™˜
        text = re.sub(r'\n', '. ', text)
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        # ìˆ«ì + "ì›"ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì½ê¸° 
        text = re.sub(r'(\d+)ì›', r'\1 ì›', text)  
        # ì¤‘ë³µ ë¬¸ì¥ë¶€í˜¸ ì •ë¦¬
        text = re.sub(r'\.\.+', '.', text) # .. -> .
        text = re.sub(r'[!?.]+\.', '.', text) # !. or ?. -> .
        text = re.sub(r'\s*\.\s*', '. ', text) # ë§ˆì¹¨í‘œ ì£¼ë³€ ê³µë°± ì •ë¦¬
        return text.strip()

# 25.04.30 def text_to_speech(text, lang='ko'): -> pygmae ì¬ìƒ : mp3 ì €ì¥ ê¸°ëŠ¥ ì˜µì…˜
def text_to_speech(text, lang='ko'):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # TTSìš© í…ìŠ¤íŠ¸ ì •ì œ 
        clean_text = clean_text_for_tts(text)
        print(f"\n[TTSìš© ì •ì œëœ í…ìŠ¤íŠ¸]\n{clean_text}")
        
        filename = f"speech_{str(uuid.uuid4())[:8]}.mp3"
        # 25.04.30 text -> clean_text ìˆ˜ì •
        tts = gTTS(text=clean_text, lang=lang)
        tts.save(filename)
        
        pygame.mixer.init()
        pygame.mixer.music.load(filename)
        pygame.mixer.music.play()
        
        while pygame.mixer.music.get_busy():
            time.sleep(0.1)
            
        pygame.mixer.quit()
        os.remove(filename)
        
    except Exception as e:
        print(f"TTS ì—ëŸ¬: {str(e)}")
        if os.path.exists(filename):
            try:
                os.remove(filename)
            except:
                pass

csv_path=r"process_data.csv"

# 25.04.29 ê¸°ëŠ¥ ì¶”ê°€ : load_csv_data ë‚´ ì¸ë±ìŠ¤ ë²ˆí˜¸ ì œê±° 
def load_csv_data(csv_path):
    """CSV, Excel, PDF íŒŒì¼ ì§€ì›"""
    encodings = ['cp949', 'euc-kr', 'utf-8']
    
    for encoding in encodings:
        try:
            print(f"{encoding} ì¸ì½”ë”©ìœ¼ë¡œ CSV íŒŒì¼ ì½ê¸° ì‹œë„...")
            df = pd.read_csv(csv_path, encoding=encoding)

            # ğŸ”§ ì»¬ëŸ¼ëª… ê³µë°± ì œê±° 25.05.01 ì¶”ê°€
            df.columns = df.columns.str.strip()

            # 25.04.29 ê¸°ëŠ¥ ì¶”ê°€ : ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ë²ˆí˜¸ë©´ ì œê±°
            if df.columns[0].lower() in ['no', 'index', 'id', 'ë²ˆí˜¸', 'id'] or df.iloc[:,0].astype(str).str.match(r'^\d+$').all():
                print("ë²ˆí˜¸ ì»¬ëŸ¼ ì œê±°")
                df = df.iloc[:, 1:]

            # 25.04.29 ê¸°ëŠ¥ ì¶”ê°€ : í•„ìš”í•œ ì—´ë§Œ ì„ íƒ -> 05.02 ë¶„ë¥˜ ë‚´ ë””ì¹´í˜ì¸ë©”ë‰´ ìˆ˜ì • ë° ì½”ë“œë‚´ 'ë¶„ë¥˜'ì¶”ê°€ 
            selected_cols = ['ì´ë¦„', 'ê°€ê²©', 'ë¶„ë¥˜', 'HOT/ICE']
            df = df[selected_cols]

            # í…ìŠ¤íŠ¸ ê²°í•© 
            # 25.05.02 ë¶„ë¥˜ì •ë³´ ì¶”ê°€
            texts = df.apply(lambda row: f"{row['ì´ë¦„']} {row['ê°€ê²©']}ì›. ë¶„ë¥˜: {row['ë¶„ë¥˜']}.", axis=1).tolist()
            print(f"CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ: {len(texts)}ê°œì˜ í–‰")
            return texts
        
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"CSV ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            return None
    
    print("\nCSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ ë°©ë²• ì¤‘ í•˜ë‚˜ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”:")
    print("1. Excelì—ì„œ:")
    print("   - 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥' ì„ íƒ")
    print("   - íŒŒì¼ í˜•ì‹ì„ 'CSV (ì‰¼í‘œë¡œ ë¶„ë¦¬) (*.csv)' ì„ íƒ")
    print("2. ë©”ëª¨ì¥ì—ì„œ:")
    print("   - 'ë‹¤ë¥¸ ì´ë¦„ìœ¼ë¡œ ì €ì¥' ì„ íƒ")
    print("   - ì¸ì½”ë”©ì„ 'ANSI' ì„ íƒ")
    return None, None

def load_data(any_path):
    """CSV, Excel, PDF íŒŒì¼ ì§€ì›"""
    ext = os.path.splitext(any_path)[-1].lower()

    if ext == '.csv':
        return load_csv_data(any_path)
    elif ext in ['.xls', '.xlsx']:
        try:
            df = pd.read_excel(any_path, engine='openpyxl')
            print("Excel íŒŒì¼ ë¡œë“œ ì„±ê³µ")
            return process_menu_dataframe(df)
        except Exception as e:
            print(f"Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            return None
    elif ext == '.pdf':
        try:
            text =""
            doc = fitz.open(any_path)
            for page in doc:
                text += page.get_text()
            print("PDF íŒŒì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ")
            return [text]
        except Exception as e:
            print(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            return None
    else:
        print("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        return None
    
def process_menu_dataframe(df):
     """ë©”ë‰´ìš© DataFrameì„ ì²˜ë¦¬í•˜ì—¬ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
     if df.columns[0].lower() in ['no', 'index', 'id', 'ë²ˆí˜¸'] or df.iloc[:, 0].astype(str).str.match(r'^\d+$').all():
         df = df.iloc[:, 1:]
     # ë¶„ë¥˜, HOT/ICE ì¶”ê°€ 
     selected_cols = ['ì´ë¦„', 'ê°€ê²©', 'ë¶„ë¥˜', 'HOT/ICE']
     df = df[selected_cols]
    
     # í…ìŠ¤íŠ¸ ì¡°í•© ë¶„ë¥˜ ì¶”ê°€ 
     texts = df.apply(lambda row: f"{row['ì´ë¦„']} {row['ê°€ê²©']}ì›. ë¶„ë¥˜: {row['ë¶„ë¥˜']}.", axis=1).tolist()
     print(f"CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ: {len(texts)}ê°œì˜ í–‰")
     return texts


def split_into_chunks(texts, chunk_size=1000):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    chunks = []
    for text in texts:
        words = str(text).split()
        current_chunk = []
        current_size = 0
        
        for word in words:
            current_chunk.append(word)
            current_size += len(word) + 1
            if current_size >= chunk_size:
                chunks.append(' '.join(current_chunk))
                current_chunk = []
                current_size = 0
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
    
    return chunks

# 25.05.01ì¼ ê¸°ëŠ¥ ì¶”ê°€: ë°ì´í„° íƒ€ì… ë³€í™˜ ê°œì„  ì½”ë“œ 
def preprocess_dataframe(df):
    """
    ë°ì´í„°í”„ë ˆì„ ì „ì²˜ë¦¬ í•¨ìˆ˜ - ë°ì´í„° íƒ€ì… ë³€í™˜ ë° ì •ë¦¬
    """
    import pandas as pd
    import numpy as np
    
    # ì»¬ëŸ¼ëª… ê³µë°± ì œê±° ë° ì •ê·œí™”
    df.columns = df.columns.str.strip()
    
    # ìˆ«ìí˜• ì—´ ëª©ë¡
    numeric_columns = [
        "ë‹¨ë°±ì§ˆ(g)", "ë‹¹ë¥˜(g)", "ì§€ë°©(g)", "í¬í™”ì§€ë°©(g)", "íŠ¸ëœìŠ¤ì§€ë°©(g)",
        "ë‚˜íŠ¸ë¥¨(mg)", "ì½œë ˆìŠ¤í…Œë¡¤(mg)", "ì¹´í˜ì¸(mg)", "ì¹¼ë¡œë¦¬(kcal)", "íƒ„ìˆ˜í™”ë¬¼(g)"
    ]
    
    # ìˆ«ìí˜• ì—´ ë³€í™˜
    for col in numeric_columns:
        if col in df.columns:
            # ì›ë³¸ ê°’ ë°±ì—…
            original_values = df[col].copy()
            
            try:
                # ë¬¸ìì—´ë¡œ ë³€í™˜ í›„ ì •ì œ
                df[col] = df[col].astype(str).str.strip()
                # ì½¤ë§ˆ ì œê±°
                df[col] = df[col].str.replace(',', '')
                # ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì ì œê±° (ì†Œìˆ˜ì  ìœ ì§€)
                df[col] = df[col].str.replace(r'[^\d.]', '', regex=True)
                # ë¹ˆ ë¬¸ìì—´ì„ NaNìœ¼ë¡œ ë³€í™˜
                df[col] = df[col].replace('', np.nan)
                # ìˆ«ìë¡œ ë³€í™˜ (ì˜¤ë¥˜ í—ˆìš©)
                df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # ë³€í™˜ ì‹¤íŒ¨í•œ ë¶€ë¶„ í™•ì¸ ë° ê¸°ë¡
                nan_count = df[col].isna().sum()
                if nan_count > 0:
                    print(f"ê²½ê³ : '{col}' ì—´ì—ì„œ {nan_count}ê°œì˜ ê°’ì´ ìˆ«ìë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                print(f"'{col}' ì—´ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ë³µì›
                df[col] = original_values
    
    return df

# 25.04.30ì¼ ê¸°ëŠ¥ì¶”ê°€ : ì‚¬ìš©ì ì—°ë ¹ëŒ€ì™€ ì§ˆí™˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©”ë‰´ë¥¼ í•„í„°ë§
def filter_menu_by_health(menu_df, age_group=None, diseases=None):
    """
    ì‚¬ìš©ì ì—°ë ¹ëŒ€ì™€ ì§ˆí™˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©”ë‰´ë¥¼ í•„í„°ë§ - ê°œì„ ëœ ë²„ì „
    """
    try:
        filtered_df = menu_df.copy()
        # 25.05.01 ìˆ«ìí˜• ì—´ì„ floatìœ¼ë¡œ ë³€í™˜
        numeric_columns = [
        "ë‹¨ë°±ì§ˆ(g)", "ë‹¹ë¥˜(g)", "ì§€ë°©(g)", "í¬í™”ì§€ë°©(g)", "íŠ¸ëœìŠ¤ì§€ë°©(g)",
            "ë‚˜íŠ¸ë¥¨(mg)", "ì¹´í˜ì¸(mg)"
        ]
        for col in numeric_columns:
            if col in filtered_df.columns:
                try:
                    filtered_df[col] = pd.to_numeric(filtered_df[col], errors='coerce')
                except Exception as e:
                    print(f"[ê²½ê³ ] ì—´ '{col}'ì„ numericìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

        # 25.05.01 ì§ˆí™˜ì— ë”°ë¥¸ í•„í„°ë§ -> - NaN ê°’ ì²˜ë¦¬ ì¶”ê°€ .fillna(999)
        if diseases:
            if "ë‹¹ë‡¨ë³‘" in diseases:
                filtered_df = filtered_df[filtered_df["ë‹¹ë¥˜(g)"].fillna(999) <= 10]
            if "ê³ í˜ˆì••" in diseases:
                filtered_df = filtered_df[filtered_df["ë‚˜íŠ¸ë¥¨(mg)"].fillna(999) <= 100]
            if "ì‹¬ì¥ì§ˆí™˜" in diseases:
                filtered_df = filtered_df[(filtered_df["ì§€ë°©(g)"].fillna(999) <= 3) & (filtered_df["ì¹´í˜ì¸(mg)"].fillna(999) <= 100)]
            if "ê³ ì§€í˜ˆì¦" in diseases:
                filtered_df =filtered_df[(filtered_df["í¬í™”ì§€ë°©(g)"].fillna(999) <= 1.5) & (filtered_df["ì§€ë°©(g)"].fillna(999) <= 3) & (filtered_df["íŠ¸ëœìŠ¤ì§€ë°©(g)"].fillna(999) <= 0.1)]
            
         # 25.04.30ì¼ ê¸°ëŠ¥ì¶”ê°€ :  ì—°ë ¹ëŒ€ì— ë”°ë¥¸ ì˜ì–‘ ê³ ë ¤ í•„í„°ë§ - NaN ê°’ ì²˜ë¦¬ ì¶”ê°€
        if age_group:
            # 25.05.01 ì¶”ê°€ìˆ˜ì • : ì—°ë ¹ëŒ€ ê·¸ë£¹ ì •ê·œí™”
            age_normalized = age_group.lower() if isinstance(age_group, str) else None

            if age_normalized == "ì–´ë¦°ì´": # 0 ~ 12
                filtered_df = filtered_df[filtered_df["ë‹¨ë°±ì§ˆ(g)"].fillna(0) >=1]
            elif age_normalized == "ì²­ì†Œë…„": # 13 ~ 18
                filtered_df = filtered_df[filtered_df["ë‹¨ë°±ì§ˆ(g)"].fillna(0) >=0.8]

            # ì„±ì¸ ì¼ ë•Œ ì²­ë…„, ì¤‘ë…„, ì¥ë…„ì´ ë“¤ì–´ê°€ì„œ kiosk 
            # ì„±ì¸ ê·¸ë£¹ ì²˜ë¦¬ (ì²­ë…„, ì¤‘ë…„, ì¥ë…„ì´ ëª¨ë‘ ì„±ì¸ì— í¬í•¨)
            elif age_normalized in ["ì²­ë…„", "ì¤‘ë…„", "ì¥ë…„", "ì„±ì¸"]: # age_normalized == "ì„±ì¸": ì¶”ê°€
                # 25.05.02 ê³µí†µ ì„±ì¸ í•„í„° ì¶”ê°€
                filtered_df = filtered_df[filtered_df["ë‹¨ë°±ì§ˆ(g)"].fillna(0) >= 0.5]
               
                # ì„¸ë¶€ ì—°ë ¹ëŒ€ë³„ ì¶”ê°€ í•„í„°
                if age_normalized == "ì„±ì¸" or age_normalized == "ì²­ë…„":
                    # 25.05.02 ì²­ë…„ ë˜ëŠ” ì¼ë°˜ ì„±ì¸ì¼ ê²½ìš° ì¹´í˜ì¸ ì œí•œë§Œ ì ìš©
                    filtered_df = filtered_df[filtered_df["ì¹´í˜ì¸(mg)"].fillna(999) <= 200]
                elif age_normalized == "ì¤‘ë…„":
                    # ì¤‘ë…„ì€ ì§€ë°© ì œí•œ ì¶”ê°€
                    filtered_df = filtered_df[(filtered_df["ì§€ë°©(g)"].fillna(999) <= 3) & (filtered_df["í¬í™”ì§€ë°©(g)"].fillna(999) <= 1.5)]
                elif age_normalized == "ì¥ë…„":
                    # ì¥ë…„ì€ ë‚˜íŠ¸ë¥¨ê³¼ ì¹´í˜ì¸ ì œí•œ ì¶”ê°€
                    filtered_df = filtered_df[(filtered_df["ë‚˜íŠ¸ë¥¨(mg)"].fillna(999) <= 100) & (filtered_df["ì¹´í˜ì¸(mg)"].fillna(999) <= 150)]
            elif age_normalized == "ë…¸ì¸":
                # ë…¸ì¸ì€ ë‹¨ë°±ì§ˆ ë†’ê³  ì¹´í˜ì¸ ë‚®ì€ ë©”ë‰´
                filtered_df = filtered_df[(filtered_df["ë‹¨ë°±ì§ˆ(g)"].fillna(0) >= 1.5) & (filtered_df["ì¹´í˜ì¸(mg)"].fillna(999) <= 150)]

        # 25.05.01 ì¶”ê°€ ì—°ë ¹ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ í•´ë‹¹ ì—°ë ¹ëŒ€ í¬í•¨ëœ í•­ëª© í•„í„°ë§ (ë¬¸ìì—´ í¬í•¨ ê²€ìƒ‰) 
        if "ì—°ë ¹" in filtered_df.columns and age_group:
            # 25.05.02 ì¶”ê°€ : ì„±ì¸ ê²€ìƒ‰ ì‹œ ì²­ë…„, ì¤‘ë…„, ì¥ë…„ í¬í•¨ ì²˜ë¦¬ 
            if age_normalized == "ì„±ì¸":
                adult_filter = (filtered_df["ì—°ë ¹"].str.contains("ì„±ì¸", case=False, na=False) | 
                                filtered_df["ì—°ë ¹"].str.contains("ì²­ë…„", case=False, na=False) | 
                                filtered_df["ì—°ë ¹"].str.contains("ì¤‘ë…„", case=False, na=False) | 
                                filtered_df["ì—°ë ¹"].str.contains("ì¥ë…„", case=False, na=False))
                filtered_df = filtered_df[adult_filter]
            else:
                filtered_df = filtered_df[filtered_df["ì—°ë ¹"].str.contains(age_group, case=False, na=False)]
        
        # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì›ë³¸ ë°ì´í„°ì˜ ì¼ë¶€ ë°˜í™˜
        if filtered_df.empty and menu_df.shape[0] > 0:
            print(f"í•„í„°ë§ ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ ë©”ë‰´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return menu_df.head(3)  # ê¸°ë³¸ì ìœ¼ë¡œ ìƒìœ„ 3ê°œ ë©”ë‰´ ë°˜í™˜
        return filtered_df
    
    except Exception as e:
        import traceback
        log_error(traceback.format_exc())
        print(f"í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return menu_df  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ ë°ì´í„° ë°˜í™˜
 
# 25.04.30ì¼ ê¸°ëŠ¥ì¶”ê°€ : ë¹ ë¥¸ ì¶”ì²œ -> 05.01 ì¼ë¶€ ìˆ˜ì • -> 05.02 ì¶”ê°€
def recommend_by_age(menu_df, age_group: str, top_n: int = 3):
    """
    ì—°ë ¹ëŒ€ ê¸°ë°˜ ë¹ ë¥¸ ì¶”ì²œ í•¨ìˆ˜
    """
    try:
         # 05.01 ì¼ë¶€ ìˆ˜ì • : ì—°ë ¹ëŒ€ ì •ê·œí™”
        age_normalized = age_group.strip().lower() if isinstance(age_group, str) else None
        # í•„í„°ë§ëœ ë©”ë‰´ ê°€ì ¸ì˜¤ê¸°
        filtered_df = filter_menu_by_health(menu_df, age_group=age_group)
        # ê²°ê³¼ ìˆëŠ”ì§€ í™•ì¸
        if filtered_df.empty:
            return f"{age_group}ì—ê²Œ ì í•©í•œ ë©”ë‰´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”."
        
        # ì¸ê¸°ìˆœ ë˜ëŠ” ëœë¤ ì¶”ì²œ if, else ì¶”ê°€ 
        if len(filtered_df) <= top_n:
            recommended = filtered_df.sample(n=min(top_n, len(filtered_df))) # í•„í„°ë§ëœ ê²°ê³¼ê°€ top_në³´ë‹¤ ì ìœ¼ë©´ ì „ì²´ ë°˜í™˜
        else:
            recommended = filtered_df.sample(n=top_n)  # ëœë¤ ì¶”ì²œ

        # ì¶”ì²œ ë©”ë‰´ ëª©ë¡ ìƒì„±
        items = recommended['ì´ë¦„'].tolist()
        return f"{age_group}ì—ê²Œ ì¶”ì²œë˜ëŠ” ë©”ë‰´ì…ë‹ˆë‹¤: " + ", ".join(items) + "."
   
    except Exception as e:
        import traceback
        log_error(traceback.format_exc())
        return "ì¶”ì²œ ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜ ë°”ëë‹ˆë‹¤."

 # 25.04.30ì¼ ê¸°ëŠ¥ì¶”ê°€ : ì—°ë ¹ + ì§ˆí™˜ì„ ëª¨ë‘ ê³ ë ¤í•œ ê±´ê°• ë§ì¶¤ ì¶”ì²œ í•¨ìˆ˜
def recommend_by_age_and_disease(menu_df, age_gorup: str = None, diseases: list =None, top_n: int =3):
    """
    ì—°ë ¹ + ì§ˆí™˜ì„ ëª¨ë‘ ê³ ë ¤í•œ ê±´ê°• ë§ì¶¤ ì¶”ì²œ í•¨ìˆ˜
    """
    try:
         # í•„í„°ë§ëœ ë©”ë‰´ ê°€ì ¸ì˜¤ê¸°
        filtered_df = filter_menu_by_health(menu_df, age_group=age_gorup, diseases=diseases)
        # ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
        if filtered_df.empty:
            return "ì¡°ê±´ì— ë§ëŠ” ê±´ê°• ë©”ë‰´ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”"
        
        # ì¸ê¸°ìˆœ ë˜ëŠ” ëœë¤ ì¶”ì²œ
        recommended = filtered_df.sample(n=min(top_n, len(filtered_df)))  
         # ì¶”ì²œ ë©”ë‰´ ëª©ë¡ ìƒì„±
        items = recommended['ì´ë¦„'].tolist()

        cond_text = ""
        if age_gorup:
            cond_text += f"{age_gorup}" + " "
        if diseases:
            cond_text += f"{', '.join(diseases)} ì§ˆí™˜ì„ ê³ ë ¤í•œ "
        return f"{cond_text.strip()} ë§ì¶¤ ì¶”ì²œ ë©”ë‰´ì…ë‹ˆë‹¤: " + ", ".join(items) + "."
    # 25.05.02 try, Exception ì¶”ê°€ 
    except Exception as e:
        import traceback
        log_error(traceback.format_exc())
        return f"ì¶”ì²œ ë„ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜ ë°”ëë‹ˆë‹¤."

# ì™¸ë¶€í™˜ê²½ì—ì„œ ë¹ ë¥´ê²Œ ë©”ë‰´ëª…ë§Œ ë½‘ê¸°
def recommend_menu_only(menu_df, age_group=None, diseases=None, top_n=3):
    """
    ì‚¬ìš©ì ì¡°ê±´ì— ë”°ë¼ ì¶”ì²œ ë©”ë‰´ ì´ë¦„ë§Œ ë°˜í™˜í•œë‹¤. 
    """
    filtered = filter_menu_by_health(menu_df, age_group, diseases)
    if filtered.empty:
        return ["ì¶”ì²œí•  ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤."]
    return filtered.sort_values(by="ë‹¨ë°±ì§ˆ(g)", ascending=False)["ì´ë¦„"].head(top_n).tolist()

# 25.04.29 ê¸°ëŠ¥ ì¶”ê°€ : 'RAG ì‘ë‹µ ì „ì²˜ë¦¬ ë° í¬ë§·íŒ… í•¨ìˆ˜
def preprocess_rag_response(response_text, menu_df=None):
    '''RAG ì‘ë‹µ ì „ì²˜ë¦¬ ë° í¬ë§·íŒ… í•¨ìˆ˜'''
     # ë©”ë‰´ê°€ ì—†ëŠ” ê²½ìš° ê°„ê²°í•˜ê²Œ ì‘ë‹µ ìƒì„± => ì¡°ê±´ì´ ì¢ì€ ê´€ê³„ë¡œ ìˆ˜ì •í•œë‹¤.
    if any(keyword in response_text for keyword in ["ì—†ëŠ” ë©”ë‰´", "ì œê³µí•˜ì§€ ì•ŠëŠ”", "ì—†ìŠµë‹ˆë‹¤", "ì£„ì†¡í•©ë‹ˆë‹¤"]):
    # if "ì—†ëŠ” ë©”ë‰´" in response_text or "ì œê³µí•˜ì§€ ì•ŠëŠ” ë©”ë‰´" in response_text:
        clean_response = "ì£„ì†¡í•©ë‹ˆë‹¤. ì£¼ë¬¸í•˜ì‹  ë©”ë‰´ëŠ” í˜„ì¬ ì œê³µí•˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. "

        # 25.05.02 ê¸°ëŠ¥ ê³ ë„í™” : ëœë¤ ì¶”ì²œ, ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ ì¶”ì²œ, ê°„ê²°í•œ ì¶”ì²œ 
        # ë©”ë‰´ ì •ë³´ê°€ ìˆë‹¤ë©´ ê°„ê²°í•œ ì¶”ì²œ ì¶”ê°€ 
        # ëœë¤í•˜ê²Œ ë‹¤ì–‘í•œ ì¶”ì²œì„ ì œê³µ
        # ì»¤í”¼, ì°¨/í‹°, ìŠ¤ë¬´ë”” ë“± ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ì—ì„œ ì¶”ì²œ
        if menu_df is not None:
            if 'ë¶„ë¥˜' in menu_df.columns:
                categories = menu_df['ë¶„ë¥˜'].unique()
                sample_categories = categories if len(categories) <= 3 else pd.Series(categories).sample(3).tolist()
           
                sample_menus = []
                for category in sample_categories:
                    category_items = menu_df[menu_df['ë¶„ë¥˜'] == category].sample(1)
                    if not category_items.empty:
                        sample_menus.append(category_items.iloc[0]['ì´ë¦„'])

                if sample_menus:
                    clean_response += "ëŒ€ì‹  ë‹¤ìŒ ë©”ë‰´ëŠ” ì–´ë–¨ê¹Œìš”? "
                    clean_response += ", ".join(sample_menus) + "." 
            else:         
               # ë¶„ë¥˜ê°€ ì—†ëŠ” ê²½ìš° ëœë¤ ì¶”ì²œ 
                coffee_items = menu_df[menu_df['ì´ë¦„'].str.contains('ì»¤í”¼|ì•„ë©”ë¦¬ì¹´ë…¸|ë¼ë–¼', case=False, na=False)].head(3)
                if not coffee_items.empty:
                     clean_response += "ëŒ€ì‹  ë‹¤ìŒ ë©”ë‰´ëŠ” ì–´ë–¨ê¹Œìš”? "
                     menu_list = coffee_items['ì´ë¦„'].tolist()
                     clean_response += ", ".join(menu_list) + "."
        return clean_response
        # ì¼ë°˜ ì‘ë‹µ ì •ì œ

    # 04.30 ì¶”ê°€ : ë§íˆ¬ ë‹¤ë“¬ê¸°
    replacements = {
        "ë§ì´ë“¤ ì°¾ìœ¼ì„¸ìš”" : "ë§ì´ë“¤ ì¢‹ì•„í•˜ì‹œë”ë¼ê³ ìš”",
        "ê´œì°®ìœ¼ì‹¤ ê±°ì˜ˆìš”" : "ì¢‹ì•„í•˜ì‹¤ ê±°ì˜ˆìš”",
        "ë“œì…”ë³´ì„¸ìš”" : "í•œ ë²ˆ ë“œì…”ë³´ì‹œëŠ” ê²ƒë„ ì¢‹ì•„ìš”",
        # 25.05.02 ì •ì œë§íˆ¬ ì¶”ê°€ 
        "ì‹œë„í•´ ë³´ì„¸ìš”": "ì‹œë„í•´ ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”",
        "ë§›ìˆì„ ê±°ì˜ˆìš”": "ë§›ìˆì„ ê±°ë¼ê³  ìƒê°í•´ìš”",
        "ì£¼ë¬¸í•˜ì‹œê² ì–´ìš”": "ì£¼ë¬¸í•´ ë³´ì‹œëŠ” ê±´ ì–´ë–¨ê¹Œìš”",
        "ëŒ€í‘œì ì¸ ë©”ë‰´": "ëŒ€í‘œ ë©”ë‰´",
        "ì¸ê¸° ë©”ë‰´": "ì¸ê¸° ìˆëŠ” ë©”ë‰´",
        "ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤": "ì¶”ì²œí•´ ë“œë ¤ìš”",
    }
    for k, v in replacements.items():
        response_text = response_text.replace(k, v)

    # ë„ì–´ì“°ê¸° ë° ë¬¸ì¥ ì •ë¦¬
    response_text = re.sub(r'\s+', ' ', response_text)  # ì¤‘ë³µ ê³µë°± ì œê±°
    response_text = re.sub(r'\.+', '.', response_text)  # ì¤‘ë³µ ë§ˆì¹¨í‘œ ì œê±°
    response_text = re.sub(r'\.\s*\.', '.', response_text)  # ë§ˆì¹¨í‘œ ê°„ê²© ì •ë¦¬
    
    return response_text

# 25.05.01 ì¶”ê°€ -> 05.05 ì§ˆë¬¸ íŒ¨í„´ ì¸ì‹ ë° ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ê°€ê²© ì •ë³´ + ì™¸ì— ì •ë³´ í¬í•¨ ìˆ˜ì •
def identify_menu_type(query, menu_df):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë©”ë‰´ ì´ë¦„ì„ ê°ì§€í•˜ê³  HOT/ICE ì—¬ë¶€ í™•ì¸
    """
    print(f"[DEBUG] identify_menu_type - query: {query}")
    print(f"[DEBUG] menu_df shape: {menu_df.shape}")
    print(f"[DEBUG] menu_df columns: {menu_df.columns.tolist()}")

    # ë©”ë‰´ ì´ë¦„ ëª©ë¡ ìˆ˜ì • -> ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬ ( ë” ê¸´ ë©”ë‰´ ë¶€í„° ê²€ì‚¬)
    #menu_names = menu_df['ì´ë¦„'].unique().tolist()
    menu_names = sorted(menu_df['ì´ë¦„'].unique().tolist(), key=len, reverse=True)
    
    hot_keywords =['ëœ¨ê±°ìš´', 'í•«', 'hot', 'Hot', 'HOT', 'ë”°ë“¯í•œ', 'ë”°ëœ»í•˜ê²Œ', 'ëœ¨ê²ê²Œ', 'í•«ëœ¨', 'ëœ¨ëœ¨', "ë”°ë”°", 'ì•„ì£¼ ëœ¨ê²ê²Œ']
    ice_keywords = ['ì°¨ê°€ìš´', 'ì‹œì›í•œ', 'ì•„ì´ìŠ¤', 'ice', 'Ice', 'ICE', 'ì‹œì›í•˜ê²Œ', 'ì°¨ê°‘ê²Œ', 'ì•„ì´ìŠ¤ë¡œ', 'ì“°ì›', 'ì‹œì›', 'ì‹œì´ì›', 'ì•„ì£¼ ì°¨ê°‘ê²Œ']

    # ë©”ë‰´ ì´ë¦„ ê°ì§€ (ê¸¸ì´ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ë©”ë‰´ë¥¼ ì²´í¬)
    # detected_menu = None
    # 25.05.05 [] ìˆ˜ì •
    detected_menus = []  
    for menu in menu_names:
        if menu in query:
        # detected_menu = menu
            detected_menus.append(menu)
    # ë©”ë‰´ ì´ë¦„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ë‹¤ë©´ í¼ì§€ ë§¤ì¹­ ì‹œë„
    if not detected_menus:
        query_words = query.split()
        for menu in menu_names:
            menu_words = menu.split()
            # ë©”ë‰´ ì´ë¦„ì˜ ì£¼ìš” ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if any(word in query_words for word in menu_words if len(word) > 1):
                possible_match = True
                for word in menu_words:
                    if len(word) > 1 and word not in query:
                        possible_match = False
                        break
                if possible_match:
                    detected_menus.append(menu) # ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ 
                    break # í¼ì§€ ë§¤ì¹­ì€ ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ 
    # HOT/ICE ì—¬ë¶€ ê°ì§€
    is_hot = any(keyword in query for keyword in hot_keywords)
    is_ice = any(keyword in query for keyword in ice_keywords)
    
    #  25.05.05 ì¶”ê°€ ë¹„êµ ì§ˆë¬¸ íŒ¨í„´ ê°ì§€
    comparison_patterns = ['ì–´ë–¤ ê²Œ ë”', 'ì–´ëŠ ê²Œ ë”', 'ë­ê°€ ë”', 'ë¬´ìŠ¨ ê²Œ ë”', 'ì–´ë–¤ ê²ƒì´ ë”']
    is_comparison = any(pattern in query for pattern in comparison_patterns)
    
    # 25.05.05 ì¶”ê°€ ë‹¨ë§› ê´€ë ¨ í‚¤ì›Œë“œ ê°ì§€
    sweet_keywords = ['ë‹¬ì•„ìš”', 'ë‹¬ë‹¬í•œ', 'ë‹¬ì½¤í•œ', 'ë‹¨', 'ë‹¹ë„', 'ì„¤íƒ•']
    is_sweet_question = any(keyword in query for keyword in sweet_keywords)
    
    # 25.05.05 ì¶”ê°€ ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
    print(f"[DEBUG] detected_menus: {detected_menus}")
    print(f"[DEBUG] is_comparison: {is_comparison}")
    print(f"[DEBUG] is_sweet_question: {is_sweet_question}")
    # ê²°ê³¼ ë°˜í™˜
    if detected_menus:
        # HOT/ICE ì²˜ë¦¬ëŠ” ì²« ë²ˆì§¸ ë©”ë‰´ë§Œ í™•ì¸
        first_menu = detected_menus[0]

        #if "(HOT)" in first_menu or "í•«" in first_menu:
        #    return first_menu, "HOT", is_comparison, is_sweet_question
         # ì´ ë¶€ë¶„ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤
        # ì‹¤ì œ ë©”ë‰´ê°€ HOT/ICEë¥¼ ëª…ì‹œí•˜ê³  ìˆëŠ”ì§€ í™•ì¸
        menu_data = menu_df[menu_df['ì´ë¦„'] == first_menu]
        if not menu_data.empty:
        # ë©”ë‰´ ë°ì´í„°ì—ì„œ HOT/ICE ì •ë³´ë¥¼ í™•ì¸
            menu_temp_types = menu_data['HOT/ICE'].unique()
        
        # í•˜ë‚˜ì˜ ì˜¨ë„ íƒ€ì…ë§Œ ìˆëŠ” ê²½ìš°
        if len(menu_temp_types) == 1 and not pd.isna(menu_temp_types[0]):
            return detected_menus, menu_temp_types[0], is_comparison, is_sweet_question
         
        # ì˜¨ë„ íƒ€ì…ì´ ì—†ëŠ” ê²½ìš°ì—ë„ 4ê°œì˜ ê°’ì„ ë°˜í™˜
        return detected_menus, None, is_comparison, is_sweet_question
        # ì§ˆë¬¸ì—ì„œ HOT/ICE ì„ í˜¸ë„ íŒŒì•…
        # if is_hot:
        #     return detected_menus, "HOT", is_comparison, is_sweet_question
        # elif is_ice:
        #     return detected_menus, "ICE", is_comparison, is_sweet_question
        # else:
        #     return None, None, is_comparison, is_sweet_question # 2ê°œ -> 4ê°œ ìˆ˜ì • 
    else:
        return None, None, is_comparison, is_sweet_question  # ë©”ë‰´ ê°ì§€ ì‹¤íŒ¨
# 25.05.01 ëŒ€í™” ì´ë ¥ ì²˜ë¦¬ ì¶”ê°€ , top_k = 8ë¡œ ìˆ˜ì •
def rag_pipeline(query: str, context_chunks: list, embedder, index, top_k: int = 8, menu_df=None, conversation_history=None) -> str:

    """RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - ëŒ€í™” ì´ë ¥ ì²˜ë¦¬ ì¶”ê°€  - ëŒ€í™” ì´ë ¥ ì²˜ë¦¬ ë° ì‘ë‹µ í’ˆì§ˆ ê°œì„ """
    
    # ëŒ€í™” ì´ë ¥ì´ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
    if conversation_history and menu_df is not None:
        # ë©”ë‰´ ì´ë¦„ê³¼ HOT/ICE ì—¬ë¶€ ê°ì§€ 2ê°œ + 25.05.05 ë‹¹ë„ ì¶”ê°€ 2ê°œ == ì´ 4ê°œ 
        #menu_name, temp_type = identify_menu_type(query, menu_df)
        #menu_name, temp_type, is_comparison, is_sweet_question = identify_menu_type(query, menu_df)
        detected_menus, temp_type, is_comparison, is_sweet_question = identify_menu_type(query, menu_df)
        
        # ëŒ€í™” ì´ë ¥ì— ë³´ë¥˜ ì¤‘ì¸ ë©”ë‰´ê°€ ìˆê³ , í˜„ì¬ ì§ˆë¬¸ì—ì„œ ì˜¨ë„ ì„ í˜¸ë„ê°€ ì–¸ê¸‰ëœ ê²½ìš°
        if conversation_history.get('pending_menu') and not detected_menus:
            prev_menu = conversation_history['pending_menu']
            
            # ì˜¨ë„ ì„ í˜¸ë„ ê°ì§€ 25.05.02 ì¼ë¶€ ë‹¨ì–´ ì¶”ê°€ 
            hot_keywords = ['ë”°ëœ»í•œ', 'ëœ¨ê±°ìš´', 'í•«', 'hot', 'Hot', 'HOT', 'í•«ëœ¨', 'ëœ¨ëœ¨' ,"ë”°ë”°" 'ë”°ë“¯í•œ', 'ë”°ëœ»í•˜ê²Œ', 'ëœ¨ê²ê²Œ', 'ì•„ì£¼ ëœ¨ê²ê²Œ' ]
            ice_keywords = ['ì°¨ê°€ìš´', 'ì‹œì›í•œ', 'ì•„ì´ìŠ¤', 'ice', 'Ice', 'ICE', 'ì“°ì›', 'ì‹œì›', 'ì‹œì´ì›', 'ì°¨ê°‘ê²Œ', 'ì•„ì´ìŠ¤ë¡œ', 'ì•„ì£¼ ì°¨ê°‘ê²Œ']
            
            if any(keyword in query.lower() for keyword in hot_keywords):
                temp_type = "HOT"
                filtered_menu = menu_df[(menu_df['ì´ë¦„'] == prev_menu) & 
                                       ((menu_df['HOT/ICE'] == temp_type) | 
                                        (menu_df['HOT/ICE'].isna()))]  # HOT/ICE ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ NaNì¸ ê²½ìš°ë„ í¬í•¨
                if not filtered_menu.empty:
                    price = filtered_menu.iloc[0]['ê°€ê²©']
                    conversation_history['pending_menu'] = None  # ë³´ë¥˜ ë©”ë‰´ ì²˜ë¦¬ ì™„ë£Œ
                    return f"ë„¤, ë”°ëœ»í•œ {prev_menu} ê°€ê²©ì€ {price}ì›ì…ë‹ˆë‹¤."
                    
            elif any(keyword in query.lower() for keyword in ice_keywords):
                temp_type = "ICE"
                filtered_menu = menu_df[(menu_df['ì´ë¦„'] == prev_menu) & ((menu_df['HOT/ICE'] == temp_type) | 
                                        (menu_df['HOT/ICE'].isna()))]  # HOT/ICE ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ NaNì¸ ê²½ìš°ë„ í¬í•¨
                if not filtered_menu.empty:
                    price = filtered_menu.iloc[0]['ê°€ê²©']
                    conversation_history['pending_menu'] = None  # ë³´ë¥˜ ë©”ë‰´ ì²˜ë¦¬ ì™„ë£Œ
                    return f"ë„¤, ì°¨ê°€ìš´ {prev_menu} ê°€ê²©ì€ {price}ì›ì…ë‹ˆë‹¤."
        
         # ë©”ë‰´ ê°ì§€ëìœ¼ë‚˜ HOT/ICE ì—¬ë¶€ê°€ ë¯¸ì§€ì •ì¸ ê²½ìš° => menu_name => deteã„¹cted_menus ë³€ê²½ (25.05.05)
        if detected_menus and not temp_type:
            first_menu = detected_menus[0]  # ì²« ë²ˆì§¸ ë©”ë‰´ ê°€ì ¸ì˜¤ê¸°
            # HOT/ICE ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸ (ìˆ˜ì •ëœ ì½”ë“œ)
            hot_available = len(menu_df[(menu_df['ì´ë¦„'] == first_menu) &  # menu_nameì„ first_menuë¡œ ë³€ê²½
                                      ((menu_df['HOT/ICE'] == 'HOT') | 
                                        (menu_df['HOT/ICE'].isna()))]) > 0
            
            ice_available = len(menu_df[(menu_df['ì´ë¦„'] == first_menu) & 
                                      ((menu_df['HOT/ICE'] == 'ICE') | 
                                        (menu_df['HOT/ICE'].isna()))]) > 0
            
            if hot_available and ice_available: # menu_name => first_menu ë³€ê²½ 
                # ëŒ€í™” ì´ë ¥ì— ë³´ë¥˜ ë©”ë‰´ ì €ì¥
                conversation_history['pending_menu'] = first_menu
                return f"{first_menu} ì£¼ë¬¸í•˜ì…¨ë„¤ìš”. ë”°ëœ»í•œ ê²ƒìœ¼ë¡œ ë“œë¦´ê¹Œìš”, ì•„ë‹ˆë©´ ì°¨ê°€ìš´ ê²ƒìœ¼ë¡œ ë“œë¦´ê¹Œìš”?"
            elif hot_available:
                price = menu_df[(menu_df['ì´ë¦„'] == first_menu) & 
                               ((menu_df['HOT/ICE'] == 'HOT') | 
                                (menu_df['HOT/ICE'].isna()))].iloc[0]['ê°€ê²©']
                return f"{first_menu}ëŠ” ë”°ëœ»í•œ ë©”ë‰´ë¡œë§Œ ì œê³µë©ë‹ˆë‹¤. ê°€ê²©ì€ {price}ì›ì…ë‹ˆë‹¤."
            elif ice_available:
                price = menu_df[(menu_df['ì´ë¦„'] == first_menu) & 
                               ((menu_df['HOT/ICE'] == 'ICE') | 
                                (menu_df['HOT/ICE'].isna()))].iloc[0]['ê°€ê²©']
                return f"{first_menu}ëŠ” ì°¨ê°€ìš´ ë©”ë‰´ë¡œë§Œ ì œê³µë©ë‹ˆë‹¤. ê°€ê²©ì€ {price}ì›ì…ë‹ˆë‹¤."
  
    # 25.05.02 íŠ¹ë³„í•œ ì§ˆë¬¸ íŒ¨í„´ ì²˜ë¦¬
    if any(keyword in query.lower() for keyword in ["ë‹¨ ìŒë£Œ", "ë‹¬ë‹¬í•œ", "ë‹¬ì½¤í•œ", "ë‹¨ ë©”ë‰´", "ë‹¹ë„ê°€ ë†’ì€", "ì•„ì£¼ ë‹¨"]):
        # ë‹¨ ìŒë£Œ ì¶”ì²œ ë¡œì§
        if menu_df is not None and "ë‹¹ë¥˜(g)" in menu_df.columns:
            # ë‹¹ë¥˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë‹¹ë¥˜ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
            sweet_menu = menu_df.sort_values(by="ë‹¹ë¥˜(g)", ascending=False).head(3)
            if not sweet_menu.empty:
                menu_list = sweet_menu['ì´ë¦„'].tolist()
                return f"ë‹¬ì½¤í•œ ë©”ë‰´ë¥¼ ì°¾ìœ¼ì‹œëŠ”êµ°ìš”! ê°€ì¥ ë‹¬ì½¤í•œ ë©”ë‰´ëŠ” {', '.join(menu_list)}ì…ë‹ˆë‹¤. ì´ ì¤‘ì—ì„œ ì–´ë–¤ ë©”ë‰´ê°€ ì¢‹ìœ¼ì‹¤ê¹Œìš”?"
        # ì¼ë°˜ ê²€ìƒ‰ ë¡œì§
        # ê²€ìƒ‰ ëŒ€ìƒ í™•ì¥ (top_k ì¦ê°€)
        query_embed = embedder.encode([query])
        distances, indices = index.search(query_embed, min(top_k, len(context_chunks)))
        context = [context_chunks[i] for i in indices[0]]
         # í”„ë¡¬í”„íŠ¸ ê°œì„  - ë” ìì„¸í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
        model = genai.GenerativeModel('gemini-2.0-flash')
    
    if any(keyword in query.lower() for keyword in ["ì°¨ê°€ìš´ ë©”ë‰´", "ì•„ì´ìŠ¤ ë©”ë‰´", "ì‹œì›í•œ ìŒë£Œ", "ì‹œì›í•œ ë©”ë‰´"]):
        # ì°¨ê°€ìš´ ë©”ë‰´ ì¶”ì²œ ë¡œì§
        if menu_df is not None and "HOT/ICE" in menu_df.columns:
            ice_menu = menu_df[menu_df['HOT/ICE'] == 'ICE'].sample(min(3, len(menu_df[menu_df['HOT/ICE'] == 'ICE'])))
            if not ice_menu.empty:
                menu_list = ice_menu['ì´ë¦„'].tolist()
                return f"ì‹œì›í•œ ìŒë£Œë¥¼ ì°¾ìœ¼ì‹œëŠ”êµ°ìš”! ì¶”ì²œ ì•„ì´ìŠ¤ ë©”ë‰´ëŠ” {', '.join(menu_list)}ì…ë‹ˆë‹¤. ì–´ë–¤ ë©”ë‰´ê°€ ì¢‹ìœ¼ì‹¤ê¹Œìš”?"
    if any(keyword in query.lower() for keyword in ["ëœ¨ê±°ìš´ ë©”ë‰´", "HOT ë©”ë‰´", "ë”°ë“¯í•œ ìŒë£Œ", "ë”°ë“¯í•œ ë©”ë‰´", "í•« ë©”ë‰´"]):
        # ë”°ë“¯í•œ ë©”ë‰´ ì¶”ì²œ ë¡œì§
        if menu_df is not None and "HOT/ICE" in menu_df.columns:
            hot_menu = menu_df[menu_df['HOT/ICE'] == 'HOT'].sample(min(3, len(menu_df[menu_df['HOT/ICE'] == 'HOT'])))
            if not hot_menu.empty:
                menu_list = hot_menu['ì´ë¦„'].tolist()
                return f"ë”°ë“¯í•œ ìŒë£Œë¥¼ ì°¾ìœ¼ì‹œëŠ”êµ°ìš”! ì¶”ì²œ ë”°ë“¯í•œ ë©”ë‰´ëŠ” {', '.join(menu_list)}ì…ë‹ˆë‹¤. ì–´ë–¤ ë©”ë‰´ê°€ ì¢‹ìœ¼ì‹¤ê¹Œìš”?"

    # ì¼ë°˜ ê²€ìƒ‰ ë¡œì§
    # ê²€ìƒ‰ ëŒ€ìƒ í™•ì¥ (top_k ì¦ê°€)
    query_embed = embedder.encode([query])
    distances, indices = index.search(query_embed, min(top_k, len(context_chunks)))
    context = [context_chunks[i] for i in indices[0]]

    # í”„ë¡¬í”„íŠ¸ ê°œì„  - ë” ìì„¸í•œ ì»¨í…ìŠ¤íŠ¸ ì œê³µ
    model = genai.GenerativeModel('gemini-2.0-flash')

    # 25.05.02 ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    conversation_context = ""
    if conversation_history and conversation_history.get('previous_query') and conversation_history.get('previous_response'):
        conversation_context = f"""
        ì´ì „ ì§ˆë¬¸: {conversation_history['previous_query']}
        ì´ì „ ë‹µë³€: {conversation_history['previous_response']}
        """

     # 25.05.02 : ë©”ë‰´ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
    menu_info = ""
    if menu_df is not None:
        # HOT/ICE ì˜µì…˜ì´ ìˆëŠ” ë©”ë‰´ ëª©ë¡
        if "HOT/ICE" in menu_df.columns:
            hot_menus = menu_df[menu_df['HOT/ICE'] == 'HOT']['ì´ë¦„'].unique().tolist()
            ice_menus = menu_df[menu_df['HOT/ICE'] == 'ICE']['ì´ë¦„'].unique().tolist()
            menu_info += f"""
            HOT ë©”ë‰´: {', '.join(hot_menus[:5])} ë“± {len(hot_menus)}ê°œ
            ICE ë©”ë‰´: {', '.join(ice_menus[:5])} ë“± {len(ice_menus)}ê°œ
            """
    # 25.05.02 ë¶„ë¥˜ë³„ ë©”ë‰´ ì •ë³´ ì¶”ê°€
        if "ë¶„ë¥˜" in menu_df.columns:
            categories = menu_df['ë¶„ë¥˜'].unique()
            for category in categories:
                category_items = menu_df[menu_df['ë¶„ë¥˜'] == category]['ì´ë¦„'].unique().tolist()
                menu_info += f"{category}: {', '.join(category_items[:3])} ë“± {len(category_items)}ê°œ\n"
     # 25.05.05 ì¶”ê°€ :  ë©”ë‰´ ë¹„êµ ì§ˆë¬¸ ì²˜ë¦¬ ì¶”ê°€
    #detected_menus, _, _, is_comparison, is_sweet_question = identify_menu_type(query, menu_df)
    #detected_menus = menu_name  # menu_nameì€ ë¦¬ìŠ¤íŠ¸ì„
    # 25.05.05 ì¶”ê°€ : ë‹¹ë¥˜ ì¶”ê°€ 
    if detected_menus is not None and is_comparison and is_sweet_question:
        # ë¹„êµí•  ë©”ë‰´ë“¤ì˜ ë‹¹ë¥˜ ì •ë³´ ì°¾ê¸°
        comparison_results = []
        print(f"[DEBUG] ë¹„êµí•˜ë ¤ëŠ” ë©”ë‰´ë“¤: {detected_menus}")
        for menu in detected_menus:
            menu_data = menu_df[menu_df['ì´ë¦„'] == menu]
            print(f"[DEBUG] ë©”ë‰´ '{menu}' ê²€ìƒ‰ ê²°ê³¼: {len(menu_data)}ê°œ")

            if not menu_data.empty:
                #for idx, row in menu_data.iterrows():
                    #sugar = row.get('ë‹¹ë¥˜(g)', None)
                sugar = menu_data.iloc[0].get('ë‹¹ë¥˜(g)', None)
                print(f"[DEBUG] {menu}ì˜ ë‹¹ë¥˜ ì›ë³¸: {sugar} (íƒ€ì…: {type(sugar)})")

                if sugar is None or pd.isna(sugar):
                    sugar = 0
                elif isinstance(sugar, str):
                    import re
                    sugar = re.sub(r'[^0-9.]', '', sugar)
                    sugar = float(sugar) if sugar else 0
                else:
                    try:
                        sugar = float(sugar)
                    except:
                        sugar = 0
                        
                print(f"[DEBUG] {menu}ì˜ ë‹¹ë¥˜: {sugar}")
                comparison_results.append((menu, sugar))
                  # ê°’ì´ ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš° 0ìœ¼ë¡œ ì²˜ë¦¬
        print(f"[DEBUG] ë¹„êµ ê²°ê³¼: {comparison_results}")

        if comparison_results:
            # comparison_results.sort(key=lambda x: x[1], reverse=True)
            # sweeter_menu = comparison_results[0][0]
            # sweeter_sugar = comparison_results[0][1]
            sugars = [result[1] for result in comparison_results]
            max_sugar = max(sugars)
            min_sugar = min(sugars)
        
            # ëª¨ë“  ê°’ì´ ê°™ì€ ê²½ìš°
            if max_sugar == min_sugar:
                if max_sugar == 0:
                    return f"{' '.join(detected_menus)} ëª¨ë‘ ë‹¹ë¥˜ ì •ë³´ê°€ ì—†ì–´ì„œ ì •í™•í•œ ë¹„êµê°€ ì–´ë µìŠµë‹ˆë‹¤. ë‘˜ ë‹¤ ë¹„ìŠ·í•œ ì •ë„ì˜ ë‹¨ë§›ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤."
                else:
                    return f"{' '.join(detected_menus)} ëª¨ë‘ ë‹¹ë¥˜ í•¨ëŸ‰ì´ ê°™ì•„ì„œ({max_sugar}g) ë‹¨ë§›ì´ ë¹„ìŠ·í•©ë‹ˆë‹¤."
            # ê°€ì¥ ë‹¨ ë©”ë‰´ ì°¾ê¸°
            comparison_results.sort(key=lambda x: x[1], reverse=True)
            sweeter_menu = comparison_results[0][0]
            sweeter_sugar = comparison_results[0][1]
        
            print(f"[DEBUG] ê°€ì¥ ë‹¨ ë©”ë‰´: {sweeter_menu}, ë‹¹ë¥˜ëŸ‰: {sweeter_sugar}")
        
            # ë‹¹ë¥˜ ê°’ì´ 0ì¸ ê²½ìš°
            if sweeter_sugar == 0:
                return f"ë‘ ë©”ë‰´ ëª¨ë‘ ë‹¹ë¥˜ ë°ì´í„°ê°€ ì—†ì–´ì„œ ì •í™•í•œ ë¹„êµê°€ ì–´ë µìŠµë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì•„ë©”ë¦¬ì¹´ë…¸ëŠ” ë‹¨ë§›ì´ ê±°ì˜ ì—†ê³ , ì¹´í˜ë¼ë–¼ëŠ” ìš°ìœ ë¡œ ì¸í•´ ì•½ê°„ì˜ ë‹¨ë§›ì´ ìˆìŠµë‹ˆë‹¤."
                    
            # ì •ìƒì ì¸ ë¹„êµ ë‹µë³€
            return f"{sweeter_menu}ì´ ë” ë‹¬ì•„ìš”. {sweeter_menu}ì˜ ë‹¹ë¥˜ í•¨ëŸ‰ì€ {sweeter_sugar}gì…ë‹ˆë‹¤."
        else:
            return "ì„ íƒí•˜ì‹  ë©”ë‰´ì˜ ë‹¹ë¥˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”."
            
        #return f"{comparison_results[0][0]}ì´ ë” ë‹¬ì•„ìš”. {sweeter_menu}ì˜ ë‹¹ë¥˜ í•¨ëŸ‰ì€ {sweeter_sugar}gì…ë‹ˆë‹¤."
    # 25.05.02 ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì¶”ê°€ -> 25.05.05 ì¶”ê°€ : 9, 10, 11ë²ˆ ì¶”ê°€ 
    prompt = f"""ë‹¤ìŒ ë°ì´í„°ì™€ ì´ì „ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì¹´í˜ ë©”ë‰´ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

        ë©”ë‰´ ë°ì´í„°:
        {' '.join(context)}

        ë©”ë‰´ ë¶„ë¥˜ ì •ë³´:
        {menu_info}

        {conversation_context}

        ì§ˆë¬¸: {query}

        ë‹µë³€ ê°€ì´ë“œë¼ì¸:
        1. ì‚¬ëŒì´ ì§ì ‘ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
        2. íŠ¹ìˆ˜ë¬¸ìë‚˜ ë§ˆí¬ë‹¤ìš´ í¬ë§·ì€ ì‚¬ìš©í•˜ì§€ ë§ê³ , ìŒì„±ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆì„ ë•Œ ìì—°ìŠ¤ëŸ½ê²Œ ë“¤ë¦¬ë„ë¡ í•´ì£¼ì„¸ìš”.
        3. ë©”ë‰´ ì¶”ì²œì„ í•  ë•ŒëŠ” ê°€ì¥ ì í•©í•œ 2-3ê°œ í•­ëª©ë§Œ ê°„ê²°í•˜ê²Œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
        4. ê°€ê²© ì •ë³´ëŠ” ì •í™•íˆ ì œê³µí•˜ê³ , ë©”ë‰´ ì¢…ë¥˜ë‚˜ ê°œìˆ˜ë¥¼ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ì—ëŠ” ì •í™•í•œ ìˆ˜ì¹˜ì™€ ëª‡ ê°€ì§€ ì˜ˆì‹œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
        ì˜ˆì‹œ: "ì»¤í”¼(HOT) ë©”ë‰´ëŠ” ì´ 13ì¢…ë¥˜ì…ë‹ˆë‹¤. ì•„ë©”ë¦¬ì¹´ë…¸, ì¹´í˜ë¼ë–¼, ë°”ë‹ë¼ë¼ë–¼ ë“±ì´ ìˆì–´ìš”."
        5. ê°œìˆ˜ì™€ ê°€ê²©ì„ ë¬¼ì–´ë³´ëŠ” ì§ˆë¬¸ì— ì •í™•í•œ ìˆ˜ì¹˜ì™€ ì˜ˆì‹œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
        ì˜ˆì‹œ: "ì•„ë©”ë¦¬ì¹´ë…¸ 3ê°œì˜ ê°€ê²©ì€ 7500ì›ì…ë‹ˆë‹¤."
        6. ì†ë‹˜ì´ HOT/ICEë¥¼ ëª…ì‹œí•˜ì§€ ì•Šê³  ë‹¨ìˆœíˆ ë©”ë‰´ ì´ë¦„ë§Œ ë§í–ˆë‹¤ë©´, HOT/ICE ì—¬ë¶€ë¥¼ ë¬¼ì–´ë³´ì„¸ìš”.
        ì˜ˆì‹œ: "ì•„ë©”ë¦¬ì¹´ë…¸ ì£¼ë¬¸í•˜ì…¨ë„¤ìš”. ë”°ëœ»í•œ ê²ƒìœ¼ë¡œ ë“œë¦´ê¹Œìš”, ì•„ë‹ˆë©´ ì°¨ê°€ìš´ ê²ƒìœ¼ë¡œ ë“œë¦´ê¹Œìš”?"
        7. ì†ë‹˜ì´ "ë”°ëœ»í•œ ê±°ìš”" ë˜ëŠ” "ì°¨ê°€ìš´ ê±°ìš”"ë¼ê³  ëŒ€ë‹µí•˜ë©´, í•´ë‹¹í•˜ëŠ” ë©”ë‰´ì™€ ê°€ê²©ì„ ì•Œë ¤ì£¼ì„¸ìš”.
        ì˜ˆì‹œ: "ë„¤, ë”°ëœ»í•œ ì•„ë©”ë¦¬ì¹´ë…¸ ê°€ê²©ì€ 2500ì›ì…ë‹ˆë‹¤."
        8. ìŒë£Œì˜ íŠ¹ì„±(ë‹¨ ìŒë£Œ, ì“´ ìŒë£Œ, ì‹œì›í•œ ìŒë£Œ ë“±)ì„ ë¬¼ì–´ë³´ë©´ ì ì ˆí•œ ë©”ë‰´ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        ì˜ˆì‹œ: "ë‹¬ì½¤í•œ ìŒë£Œë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”? ì¹´ë¼ë©œë§ˆí‚¤ì•„ë˜, ë°”ë‹ë¼ë¼ë–¼, ì´ˆì½œë¦¿ë¼ë–¼ê°€ ê°€ì¥ ë‹¬ì½¤í•œ ë©”ë‰´ì…ë‹ˆë‹¤."
        9. ë¹„êµ ì§ˆë¬¸("ì–´ë–¤ ê²Œ ë” ë‹¬ì•„ìš”?")ì˜ ê²½ìš°, ê° ë©”ë‰´ì˜ ë‹¹ë¥˜ í•¨ëŸ‰ì„ ë¹„êµí•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
        10. ë©”ë‰´ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°, ì¼ë°˜ì ì¸ ìƒì‹ìœ¼ë¡œ ë‹µë³€í•˜ë˜ ì •í™•í•˜ê²Œ ì „ë‹¬í•˜ì„¸ìš”.
        11. ë‹¬ì½¤í•œ ì •ë„ë¥¼ ë¹„êµí•  ë•ŒëŠ” ë‹¹ë¥˜(g) ìˆ˜ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•˜ì„¸ìš”.

        ë‹µë³€:"""
    
    # 25.04.30 ì¤‘ë³µ íšŒí”¼ ë° ë‹µë³€ ë‹¤ì–‘ì„± ì¦ê°€ : ì‘ë‹µìƒì„±
    response = model.generate_content(prompt, generation_config={
        "temperature": 0.9,
        "top_p": 0.95,
        "top_k": 40,
    })

    # 25.05.02 ë¡œê¹… ë° í•™ìŠµì„ ìœ„í•œ ì‘ë‹µ ì €ì¥
    raw_response = response.text

    # 25.04.29 ì‘ë‹µ ì „ì²˜ë¦¬ ë° í¬ë§·íŒ…
    processed_response = preprocess_rag_response(response.text, menu_df)
    # í•™ìŠµ ë°ì´í„° ë¡œê¹… - ì›ë³¸ ì§ˆë¬¸, ì‘ë‹µ, ì²˜ë¦¬ëœ ì‘ë‹µ
    save_rag_response_log(query, processed_response)
    
    return processed_response

# 25.05.02 ê¸°ëŠ¥ì¶”ê°€ :  rag_log.txt íŒŒì¼ì„ í™œìš©í•œ ì§€ì† í•™ìŠµ ë¡œì§
def save_rag_response_log(query, answer, response_path="rag_log.txt"):
    """
    RAG ì§ˆì˜ì‘ë‹µ ë¡œê·¸ë¥¼ ì €ì¥í•˜ê³  í•™ìŠµì— í™œìš©í•˜ëŠ” í•¨ìˆ˜ - ê°œì„ ëœ ë²„ì „
    """
    # ë¡œê·¸ íŒŒì¼ì— ì§ˆë¬¸ê³¼ ë‹µë³€ ì €ì¥
    with open(response_path, "a", encoding="utf-8") as f:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"[ì‹œê°„] {timestamp}\n[ì§ˆë¬¸] {query}\n[ë‹µë³€] {answer}\n\n")
    
    # ì£¼ê¸°ì ìœ¼ë¡œ ë¡œê·¸ íŒŒì¼ì—ì„œ ë°ì´í„° í•™ìŠµ
    try:
        # ë¡œê·¸ íŒŒì¼ í¬ê¸°ê°€ ì¼ì • í¬ê¸° ì´ìƒì´ë©´ í•™ìŠµ ë°ì´í„°ë¡œ í™œìš©
        if os.path.getsize(response_path) > 10000:  # 10KB ì´ìƒ
            learn_from_log(response_path)
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# 25.05.02 : ë¡œê·¸ íŒŒì¼ì—ì„œ ì§ˆë¬¸-ë‹µë³€ ìŒ ì¶”ì¶œ ë° ì¸ë±ìŠ¤ ê°•í™” í•¨ìˆ˜
def learn_from_log(log_path="rag_log.txt"):
    """
    ë¡œê·¸ íŒŒì¼ì—ì„œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ì¶”ì¶œí•˜ì—¬ ì„ë² ë”© ë° ê²€ìƒ‰ ì¸ë±ìŠ¤ ê°•í™”
    """
    try:
        # ë¡œê·¸ íŒŒì¼ ì½ê¸°
        with open(log_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # ì§ˆë¬¸-ë‹µë³€ ìŒ ì¶”ì¶œ
        qa_pairs = []
        sections = content.split("\n\n")
        
        for section in sections:
            if "[ì§ˆë¬¸]" in section and "[ë‹µë³€]" in section:
                lines = section.strip().split("\n")
                question = None
                answer = None
                
                for line in lines:
                    if line.startswith("[ì§ˆë¬¸]"):
                        question = line[5:].strip()
                    elif line.startswith("[ë‹µë³€]"):
                        answer = line[5:].strip()
                
                if question and answer:
                    qa_pairs.append((question, answer))
        
        # í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ì•Œë¦¼
        print(f"ë¡œê·¸ì—ì„œ {len(qa_pairs)}ê°œì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        
        # ì—¬ê¸°ì— ì‹¤ì œ í•™ìŠµ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥
        # ì˜ˆ: fine-tuning ë˜ëŠ” ì„ë² ë”© ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸
        
        # ë¡œê·¸ íŒŒì¼ ë°±ì—… ë° ì´ˆê¸°í™” (ì„ íƒ ì‚¬í•­)
        if len(qa_pairs) > 100:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ëª¨ì´ë©´ ë°±ì—… í›„ ì´ˆê¸°í™”
            backup_file = f"{log_path}.{datetime.now().strftime('%Y%m%d%H%M%S')}"
            os.rename(log_path, backup_file)
            print(f"ë¡œê·¸ íŒŒì¼ì„ {backup_file}ë¡œ ë°±ì—…í–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"ë¡œê·¸ íŒŒì¼ í•™ìŠµ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

# 25.05.01 ëŒ€í™” ì´ë ¥ ê´€ë¦¬ ë¶€ë¶„ ì¶”ê°€  top_k => 8ë¡œ ìˆ˜ì •
def main(csv_path: str, chunk_size: int = 1000, top_k: int = 8):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""

    # ëŒ€í™” ì´ë ¥ ì´ˆê¸°í™”
    conversation_history = {
        'pending_menu': None,  # HOT/ICE ì—¬ë¶€ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë©”ë‰´ ì´ë¦„
        'previous_query': None,  # ì´ì „ ì§ˆë¬¸
        'previous_response': None  # ì´ì „ ë‹µë³€
    }
    
    prev_answer = ""
    # í™˜ê²½ ì„¤ì •
    load_dotenv()
    api_key = os.getenv('GEMINI_API_KEY')
    if not api_key:
        print("Error: GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    genai.configure(api_key=api_key)

    # CSV ë°ì´í„° ë¡œë“œ 
    print(f"CSV íŒŒì¼ '{csv_path}' ì²˜ë¦¬ ì¤‘...")
    
    # 25.05.01 menu_df- ëª¨ë“  ì»¬ëŸ¼ í¬í•¨í•˜ì—¬ ë¡œë“œ 
    try:
        menu_df = pd.read_csv(csv_path, encoding='utf-8')
        print(f"ë©”ë‰´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(menu_df)}ê°œ í•­ëª©")
    except Exception as e:
        print(f"ë©”ë‰´ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return

    # í…ìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    texts = load_csv_data(csv_path)
    if not texts:
        return
    
    # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
    chunks = split_into_chunks(texts, chunk_size)
    print(f"ì´ {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë¨")

    # ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
    embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
    embeddings = embedder.encode(chunks)
    
    # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(np.array(embeddings, dtype=np.float32))

    # ëŒ€í™”í˜• ì§ˆì˜ì‘ë‹µ ë£¨í”„
    print("\nRAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    while True:
        input_str = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: q): ")
        if input_str.lower() == 'q':
            break
            
        user_query = input_str.strip()
        if len(user_query) < 2 or not re.search(r'[ê°€-í£a-zA-Z0-9]', user_query):
            print("\nì£„ì†¡í•©ë‹ˆë‹¤, ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
            continue
        print("\në‹µë³€ ìƒì„± ì¤‘...")

        # 4.30ì¼ ì‘ë‹µ ì¤‘ë³µ ë°©ì§€ (ì´ì „ ì‘ë‹µì„ ê¸°ì–µí•˜ê³  í•„í„°ë§í•œë‹¤)
        # 25.05.02 ì½”ë“œ ìˆ˜ì •
        answer = rag_pipeline(user_query, chunks, embedder, index, top_k, menu_df, conversation_history)     
        # 25.05.02 ì¶”ê°€ : ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
        conversation_history['previous_query'] = user_query
        conversation_history['previous_response'] = answer

        # ì´ì „ ì‘ë‹µê³¼ ë„ˆë¬´ ë¹„ìŠ·í•œ ê²½ìš° ì¬ìƒì„±
        if prev_answer and answer.strip() == prev_answer.strip():
            print("ê°™ì€ ì‘ë‹µ ë°˜ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë‹¤ì‹œ ìƒì„± ì¤‘")
            answer = rag_pipeline(user_query + "ë‹¤ë¥¸ ì¶”ì²œë„ ì•Œë ¤ì¤˜", chunks, embedder, index, top_k)

        prev_answer = answer 

        # ì§ˆë¬¸ ë°›ê¸° 
        print(f"\nì§ˆë¬¸: {user_query}")
        print(f"ë‹µë³€: {answer}")
        
        print("\nTTS ë³€í™˜ ì¤‘...")
        text_to_speech(answer)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='CSV ê¸°ë°˜ RAG ì‹œìŠ¤í…œ')
    parser.add_argument('--csv', type=str, default="process_data.csv", help='CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--chunk_size', type=int, default=1000, help='ì²­í¬ í¬ê¸°')
    parser.add_argument('--top_k', type=int, default=4, help='ê²€ìƒ‰í•  ìƒìœ„ kê°œ ë¬¸ì„œ ì‚¬ìš©')
    
    args = parser.parse_args()
    try:
        main(csv_path=args.csv, chunk_size=args.chunk_size, top_k=args.top_k)
    except Exception:
        log_error(traceback.format_exc())
        print("âš  ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. error_log.txt íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")